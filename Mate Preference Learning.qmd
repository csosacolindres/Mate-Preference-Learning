---
title: "How To Learn Your Mate Preferences"
format: html
editor: visual
---

## Mate Preference Learning

**Purpose**: This model was designed to explore how might species-typical mating psychology give rise to individually tailored mate preferences. Using an agent-based model, we will test the ability of a reinforcement learning algorithm to reproduce the ideal mate preferences of N = 1,044 participants.

âœ… **Agents**: Each agent represents a participant. The agents are made up of 15 traits, an initial preference vector (10's across all traits), an initial reward vector (date mate value given preferences), memory for reward vector, memory for preference vector.

**Life Cycle:**

1.  Mate choice for n cycles using preference vector.

    1.  Each cycle, they choose a mate that maximizes mv\*received/sent

    2.  Store mv\*received/sent in memory for reward vector (needs to be constantly recalc)

    3.  Preference vector goes into preference memory

2.  Change preferences relative to memory by methods:

    1.  Random

    2.  Decreased fixed amount (need to code diff for this)

    3.  Move towards highest reward partner (and this)

3.  Mate choice for n cycles using changed preference vector

    1.  Compare max reward to max reward stored in memory (do new preferences do better than old preferences?)

        1.  If better: Store new preferences in memory & store reward in memory

        2.  If not better: Keep memory unchanged; discard new preference & reward vector.

4.  Cycle back to #2 (change preferences relative to memory by methods---for now only Random) until preferences are no longer changing.

SIMULATION

Learning Cycles:

-   change preferences

-   calculate MV

-   create choice matrix

-   mate choice cycles

    -   calculate reward

    -   choose mate

    -   update choice matrix

-   compare reward

update as necessary

Take this models reward as is (before update preferences). Save to memory.

Copy and paste to for loop that has (new) ability to change preferences.

Random Update Methods

Check if this is just anchoring to mvs and randomly changing prefs to = mvs

Methods Cycle : randomMethod, absoluteMethod, etc.

Week 4 Have functional draft for a few methods

```{r}
#PARAMETERS

# the 15 Traits
traitNames <- paste0(c("affectionate", 
                       "ambition", 
                       "artistic", 
                       "disposition", 
                       "family", 
                       "health", 
                       "humor", 
                       "intelligent", 
                       "kind", 
                       "parenting", 
                       "physatt", 
                       "religious", 
                       "resources", 
                       "sexy", 
                       "status"))

# Starting Values for Prefernces and Reward Memory. 
startPref <- 10
startRMem <- 0

# Interest Ratio (starting values)
recieved <- 1
sent <- 1

# number of males and females
maleNum <- 30
femaleNum <- 30

# All Methods
methodList <- c("randomMethod", "absoluteMethod", "absImpMethod", "allMagMethod", "magnitudeMethod", "magImpMethod", "magUpDownMethod")

# Current method(s) being used
methodList <- c("allMagMethod", "magUpDownMethod")

# absolute method(s) subtracting amount from mate preferences
abValue <- .1

# magnitude method(s) largest change value & probability of magVal going down vs up. 
magVal <- .5
downProb <- .8


# Cycles 
methodCycles <- length(methodList)
prefLearningCycles <- 3000
prefTestingCycles <- 60




```

Agent Generation

```{r}
# Human_data; PIN(3); sex(4); Ideal(235:249) Affectionate, Ambition, Artistic, Disposition, Family, Health, Humor, Intelligent, Kind, Parenting, Physical Attractiveness, Religious, Resources, Sexy, Status; Importance(283:297) " ; Self Composite(345:359) " ; Self Mate Value Composite(418) "

data <- read.csv("Human_data.csv")
data <- data[complete.cases(data[, c(6, 235:249, 345:359, 283:297, 299:213)]),]

# seperating into sexes
females <- data[data$sex == 0,]
males <- data[data$sex == 1,]

# number of participants
females <- females[sample(1:nrow(females), femaleNum),]
males <- males[sample(1:nrow(males), maleNum),]

# participant's traits 
mTraits <- males[, c(345:359)]
fTraits <- females[, c(345:359)]

# participant's importance ratings 
fImp <- females[, c(283:297)]
mImp <- males[, c(283:297)]



```

Functions

```{r}

# Mate Value Calculation : own pref vector, others trait composite
mvcalc <- function(pref, traits){
  names(pref) <- 1:15
  names(traits) <- 1:15
  mv <- 10 *(-1 *(dist(rbind(pref, traits))) + sqrt(10^2 *15)) / sqrt(10^2 *15)
  
  return(mv)
}


# Reward Calculation : interest recieved / interest sent 
rcalc <- function(mv, recieved, sent) {
  
  interestRatio <- t(recieved) / sent
  interestRatio[interestRatio > 1] <- 1
  reward <- mv * interestRatio 
  
  return(reward)
}


```

Methods

```{r}

# Random Method: Selects 1 random trait to change. Changes selected trait to random mate preference value.
randomMethod <- function(pref){
  
  random <- t(apply(pref, 1, function(y) round(runif(y, min = 0, max = 10), 1)))
  colnames(random) <- colnames(pref)
  
  changeMat <- cbind(1:nrow(pref), sample(1:15, nrow(pref), replace = T))
  pref[changeMat] <- random[changeMat]
  
  return(pref)
}
  


# Absolute Method: Selects all trait to change. Changes traits down by abValue amount.
absoluteMethod <- function(pref){
  
  absolute <- pref - abValue 
  colnames(absolute) <- colnames(pref)
  
  changeMat <- cbind(1:nrow(pref), sample(1:15, nrow(pref), replace = T))
  pref[changeMat] <- absolute[changeMat]
  
  return(pref)
}



# Absolute-Importance Method: Selects a trait to change proportional to how important the triat is to the specific participant. Changes selected trait down by abValue.  
absImpMethod <- function(pref, imp){
  
  absolute <- pref - abValue 
  colnames(absolute) <- colnames(pref)
  
  changeVec <- apply(imp, 1, function(x) sample(1:15, 1, prob = 11 - x))
  changeMat <- cbind(1:nrow(pref), changeVec)
  pref[changeMat] <- absolute[changeMat]
  
  return(pref)
}



## PROBLEM ##
# All-Magnitude Method: Selects all traits. Changes values down by mag (a value proportional to importance with a max amount that preference value can change). More important traits go down less amount. Less important traits go down less amount.
allMagMethod <- function(pref, imp, magVal){
  
  mag <- ((11-imp)/11) * magVal
  colnames(mag) <- colnames(pref)
  
  pref <- pref - mag

  return(pref)
}



# Magnitude Method: Selects 1 trait at random. Changes values down by mag (a value proportional to importance and a max amount that preference value decreses by). More important traits go down less amount. Less important traits go down less amount.
magnitudeMethod <- function(pref, imp, magVal){
  
  mag <- ((11-imp)/11) * magVal
  colnames(mag) <- colnames(pref)
  magnitude <- pref - mag
  
  changeVec <- apply(imp, 1, function(x) sample(1:15, 1))
  changeMat <- cbind(1:nrow(pref), changeVec)
  pref[changeMat] <- magnitude[changeMat]

  return(pref)
}



# Magnitude-Importance Method: Selects 1 trait proportional to how important the trait is (if more important, less likley to be picked. If less important, more likely to be picked). The the preference values decrease by mag (a value proportional to importance and a max amount that preference value decreases by). More important traits decrease less. Less important traits decrease more. 
magImpMethod <- function(pref, imp, magVal){
  
  mag <- ((11-imp)/11) * magVal
  colnames(mag) <- colnames(pref)
  magnitude <- pref - mag
  
  changeVec <- apply(imp, 1, function(x) sample(1:15, 1, prob = 11 - x))
  changeMat <- cbind(1:nrow(pref), changeVec)
  pref[changeMat] <- magnitude[changeMat]

  return(pref)
}



## PROBLEM 
# Magnitude Up-Down Method: Selects all traits. This can decrease and increase preference values. The traits increase or decrease depending on a weighted proportion (downProb). The preference values decrease by mag (a value proportional to importance and a max amount that preference value decreases by) where ore important traits decrease less. Less important traits decrease more. The preference values increase by mag where the more important traits increase more and the less important traits increase less. 
magUpDownMethod <- function(pref, imp, magVal, downProb){
  
  if(rbinom(1, 1, prob = downProb)){
    
    mag <- ((11-imp)/11) * magVal
    colnames(mag) <- colnames(pref)
    pref <- pref - mag
    
  } else {
     
    mag <- ((imp + 1)/11) * magVal
    colnames(mag) <- colnames(pref)
    
    pref <- pref + mag
    pref[pref > 10] <- 10
     
  }
  
  return(pref)
}

```

mpUpdate

```{r}

mpUpdate <- function(method = "method", pref, imp, magVal, downProb) {
  
  if(method == "randomMethod") {
    
    pref <- randomMethod(pref)
    
    } 
  
  
  
  if(method == "absoluteMethod") {
        
    pref <- absoluteMethod(pref)
    
    }
  

  
  if(method == "absImpMethod") {
    
    pref <- absImpMethod(pref, imp)
    
    }
    
  
  
  if(method == "magnitudeMethod") {
    
    pref <- magnitudeMethod(pref, imp, magVal)
    
    }
  
  
  
  if(method == "magImpMethod") {
  
    pref <- magImpMethod(pref, imp, magVal)
  
  
    }
  
  

  if(method == "allMagMethod"){
    
    pref <- allMagMethod(pref, imp, magVal)
    
    }
  
  
  
  if(method == "magUpDownMethod"){
   
    pref <- magUpDownMethod(pref, imp, magVal, downProb)
    
    }
  
 
  return(pref)
}


```

Matrices for Statistics

```{r}
# Storing Trial by trial correlations ... i didnt know where else to put this and i didnt want to put it in simulaiton... 
mTrialByTrial <- matrix(data = NA, nrow = prefLearningCycles, ncol = length(methodList)) 
fTrialByTrial <- matrix(data = NA, nrow = prefLearningCycles, ncol = length(methodList))


```

# Simulation:

```{r}


 for(u in 1:methodCycles) {
   
# re-sets inital traits after a method; if not: old method pref updates will stay for next update method. I dont want that. 
   
   fPref <- matrix(startPref, nrow(females), 15)
   colnames(fPref) <- traitNames
   
   fPrefMemory <- matrix(startPref, nrow(females), 15)
   colnames(fPrefMemory) <- traitNames
   
   fRewMemory <- matrix(startRMem, nrow(females), nrow(males))
    
   
   mPref <- matrix(startPref, nrow(males), 15)
   colnames(mPref) <- traitNames
   
   mPrefMemory <- matrix(startPref, nrow(males), 15)
   colnames(mPrefMemory) <- traitNames
   
   mRewMemory <- matrix(startRMem, nrow(males), nrow(females))

   
   # method cycled 
   method <- methodList[u]
   
   
  for(l in 1:prefLearningCycles) {
    
    # makes sure the right method is being used. 
    if(l > 1) {
      fPref <- mpUpdate(method, pref = fPref, imp = fImp, magVal = magVal, downProb = downProb)
      mPref <- mpUpdate(method, pref = mPref, imp = mImp, magVal = magVal, downProb = downProb)
    } 

    # Create choice matrix:
    fChoice <- matrix(1, nrow(females), nrow(males))
    mChoice <- matrix(1, nrow(males), nrow(females))
    
     # Calculate MV
    fMV <- t(apply(fPref, 1, function(x) apply(mTraits, 1, function (y) mvcalc(x, y))))
    mMV <- t(apply(mPref, 1, function(x) apply(fTraits, 1, function(y) mvcalc(x, y))))
    
    for(t in 1:prefTestingCycles){
      
      # Calculate Reward 
      fReward <- rcalc(fMV, mChoice, fChoice)
      mReward <- rcalc(mMV, fChoice, mChoice)
      
      
      # Choose Mate 
      fMaxReward <- cbind(1:nrow(females), apply(fReward, 1, which.max))
      mMaxReward <- cbind(1:nrow(males), apply(mReward, 1, which.max))
      
      
      
      
      # Update Choice Matrices
      fChoice[fMaxReward] <- fChoice[fMaxReward] + 1
      mChoice[mMaxReward] <- mChoice[mMaxReward] + 1
     
    
    }
    
# Commit to Memory. If new reward is higher than old reward, replace old mate preference set with new mate preference set. If not, keep old mate preference set. 
    for(f in 1:nrow(females)){
      maxNow <- max(fReward[f, ])
      maxMemory <- max(fRewMemory[f, ])
      
      if(maxNow >= maxMemory){
        fRewMemory[f, ] <- fReward[f, ]
        fPrefMemory[f, ] <- fPref[f, ]
      } else {
        fPref[f, ] <- fPrefMemory[f, ]  
        
        }
      }
    for(m in 1:nrow(males)){
      maxNow <- max(mReward[m, ])
      maxMemory <- max(mRewMemory[m, ])
        
      if(maxNow >= maxMemory){
        mRewMemory[m, ] <- mReward[m, ]
        mPrefMemory[m, ] <- mPref[m, ]
      } else{
        mPref[m, ] <- mPrefMemory[m, ]
        
      }
    } # male memory loop
    
  
  
    
    
# Saves trial by trial correlations for each method being used.
    mTrialByTrial[l, u] <- mean(diag(cor(mPrefMemory, males[235:249])))
    fTrialByTrial[l, u] <- mean(diag(cor(fPrefMemory, females[235:249])))  
    

    
  } # prefLearningCycle loop
   
# PROBLEM. MAKE THE NEW DATA.FRAME. 
# Save absoluteMethods outputs 
   # if(u == 1){
   #   mRandLearned <- mPrefMemory
   #   fRandLearned <- fPrefMemory
   #   
   # } else if(u == 2){
   #   
   #   mAbsLearned <- mPrefMemory
   #   fAbsLearned <- fPrefMemory
   #   
   # } else if(u == 3){
   #   
   #   mAbsImpLearned <- mPrefMemory
   #   fAbsImpLearned <- fPrefMemory
   #   
   # } else if(u == 4){
   #   mAbsRankLearned <- mPrefMemory
   #   fAbsRankLearned <- fPrefMemory
   #   
   # }

   
} # methodCycles loop
 


```
