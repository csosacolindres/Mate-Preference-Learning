---
title: "How To Learn Your Mate Preferences"
format: html
editor: visual
---

## Mate Preference Learning

**Purpose**: This model was designed to explore how might species-typical mating psychology give rise to individually tailored mate preferences. Using an agent-based model, we will test the ability of a reinforcement learning algorithm to reproduce the ideal mate preferences of N = 1,044 participants.

âœ… **Agents**: Each agent represents a participant. The agents are made up of 15 traits, an initial preference vector (10's across all traits), an initial reward vector (date mate value given preferences), memory for reward vector, memory for preference vector.

**Life Cycle:**

1.  Mate choice for n cycles using preference vector.

    1.  Each cycle, they choose a mate that maximizes mv\*received/sent

    2.  Store mv\*received/sent in memory for reward vector (needs to be constantly recalc)

    3.  Preference vector goes into preference memory

2.  Change preferences relative to memory by methods:

    1.  Random

    2.  Decreased fixed amount (need to code diff for this)

    3.  Move towards highest reward partner (and this)

3.  Mate choice for n cycles using changed preference vector

    1.  Compare max reward to max reward stored in memory (do new preferences do better than old preferences?)

        1.  If better: Store new preferences in memory & store reward in memory

        2.  If not better: Keep memory unchanged; discard new preference & reward vector.

4.  Cycle back to #2 (change preferences relative to memory by methods---for now only Random) until preferences are no longer changing.

Parameters

```{r}
#PARAMETERS

startPref <- 10
startRMem <- 0

startRecieved <- 1
startSent <- 1


prefLearningCycles <- 10
mateChoiceCycles <- 10000

```

Agent Generation

```{r}


# Human_data; PIN(3); sex(4); Ideal(235:249) Affectionate, Ambition, Artistic, Disposition, Family, Health, Humor, Intelligent, Kind, Parenting, Physical Attractiveness, Religious, Resources, Sexy, Status; Importance(283:297) " ; Self Composite(345:359) " ; Self Mate Value Composite(418) "

data <- read.csv("Human_data.csv")
# Sampled 10 people to chick if things are working right. 
data <- data[c(1:5, 950:954),]

males <- data[data$sex == 1,]
females <- data[data$sex == 0,]


# MALES: TRAITS ; PREFERENCE VECTOR, MEMEORY ; REWARD VECTOR, MEMORY
mTraits <- males[, c(345:359)]
mPref <- matrix(startPref, nrow(males), 15)
colnames(mPref) <- c("prefVector_affectionate", 
                            "prefVector_ambition", 
                            "prefVector_artistic", 
                            "prefVector_disposition", 
                            "prefVector_family", 
                            "prefVector_health", 
                            "prefVector_humor", 
                            "prefVector_intelligent", 
                            "prefVector_kind", 
                            "prefVector_parenting", 
                            "prefVector_physAtt", 
                            "prefVector_religious", 
                            "prefVector_resources", 
                            "prefVector_sexy", 
                            "prefVector_status")
mPrefMemory <- matrix(NA, nrow(males), 15)
colnames(mPrefMemory) <- c("prefMemory_affectionate", 
                            "prefMemory_ambition", 
                            "prefMemory_artistic", 
                            "prefMemory_disposition", 
                            "prefMemory_family", 
                            "prefMemory_health", 
                            "prefMemory_humor", 
                            "prefMemory_intelligent", 
                            "prefMemory_kind", 
                            "prefMemory_parenting", 
                            "prefMemory_physAtt", 
                            "prefMemory_religious", 
                            "prefMemory_resources", 
                            "prefMemory_sexy", 
                            "prefMemory_status")
#mRewVector <- matrix(NA, nrow(males), nrow(females))
#colnames(rewVectorM) <- c("rewVec_female1", 
                          # "rewVec_female2", 
                           #"rewVec_female3", 
                           #"rewVec_female4", 
                           #"rewVec_female5")
mRewMemory <- matrix(startRMem, nrow(males), nrow(females))
#colnames(rewMemoryM) <- c("rewMem_female1", 
                          # "rewMem_female2", 
                           #"rewMem_female3", 
                           #"rewMem_female4", 
                           #"rewMem_female5")







# FEMALES: PREFERENCE VECTOR, MEMORY ; REWARD VECTOR, MEMORY
fTraits <- females[, c(345:359)]
fPref <- matrix(startPref, nrow(females), 15)
colnames(fPref) <- c("prefVector_affectionate", 
                            "prefVector_ambition", 
                            "prefVector_artistic", 
                            "prefVector_disposition", 
                            "prefVector_family", 
                            "prefVector_health", 
                            "prefVector_humor", 
                            "prefVector_intelligent", 
                            "prefVector_kind", 
                            "prefVector_parenting", 
                            "prefVector_physAtt", 
                            "prefVector_religious", 
                            "prefVector_resources", 
                            "prefVector_sexy", 
                            "prefVector_status")

fPrefMemory <- matrix(NA, nrow(females), 15)
colnames(fPrefMemory) <- c("prefMemory_affectionate", 
                            "prefMemory_ambition", 
                            "prefMemory_artistic", 
                            "prefMemory_disposition", 
                            "prefMemory_family", 
                            "prefMemory_health", 
                            "prefMemory_humor", 
                            "prefMemory_intelligent", 
                            "prefMemory_kind", 
                            "prefMemory_parenting", 
                            "prefMemory_physAtt", 
                            "prefMemory_religious", 
                            "prefMemory_resources", 
                            "prefMemory_sexy", 
                            "prefMemory_status")
fRewVector <- matrix(NA, nrow(females), nrow(males))
#colnames(rewVectorF) <- c("rewVec_male1", 
                          # "rewVec_male2", 
                          # "rewVec_male3", 
                          # "rewVec_male4", 
                           #"rewVec_male5")
fRewMemory <- matrix(startRMem, nrow(females), nrow(males))
#colnames(rewMemoryF) <- c("rewMem_male1", 
                          # "rewMem_male2", 
                           #"rewMem_male3", 
                           #"rewMem_male4", 
                           #"rewMem_male5")


#AGENTS
mAgents <- cbind(mTraits, mPref, mPrefMemory)
fAgents <- cbind(fTraits, fPref, fPrefMemory)
# Keep traits, pref vector pref mem. For rew vector, memory and choice keep as part of the environment. 


```

Functions

```{r}

# Mate Value Calculation : own pref vector, others trait composite
mvcalc <- function(prefVector, traits){
  names(prefVector) <- 1:15
  names(traits) <- 1:15
  mv <- 10 *(-1 *(dist(rbind(prefVector, traits))) + sqrt(10^2 *15)) / sqrt(10^2 *15)
  return(mv)
}

# Reward Calculation : interest recieved, interest sent
rcalc <- function(mv, recieved, sent) {
  reward <- mv * recieved / sent
  return(reward)
}

```

SIMULATION

Learning Cycles:

-   change preferences

-   calculate MV

-   create choice matrix

-   mate choice cycles

    -   calculate reward

    -   choose mate

    -   update choice matrix

-   compare reward

update as necessary

Take this models reward as is (before update preferences). Save to memory.

Copy and paste to for loop that has (new) ability to change preferences.

Methods

```{r}

# make randomMethod only take one preferncec vector. 

# Random Method: Change row values for every col to a random number. 
randomMethod <- function(mPref, fPref){
  
  mRandom <- t(apply(mPref, 1, function(y) runif(y, min = 0, max = 10)))
  colnames(mRandom) <- colnames(mPref)
  mPref <- mRandom
  
  fRandom <- t(apply(fPref, 1, function(x) runif(x, min = 0, max = 10)))
  colnames(fRandom) <- colnames(fPref)
  fPref <- fRandom
  
  return(list(mPref, fPref))
}
  


```

```{r}

# if (first not first generation, Change Preferences: )




for(p in 1:prefLearningCycles){
  
  # make 2 randomMethods calc ( for male AND females)
  # Overide preferences save as updates come. 
  if(p > 1) {
   randomMethod(mPref, fPref) 
  }
  
  # Calculate MV
  mMVs <- t(apply(mPref, 1, function(x) apply(fTraits, 1, function(y) mvcalc(x, y))))
  fMVs <- t(apply(fPref, 1, function(x) apply(mTraits, 1, function (y) mvcalc(x, y))))
  
  # Create choice matrix:
  mChoice <- matrix(1, nrow(males), nrow(females))
  fChoice <- matrix(1, nrow(females), nrow(males))
  
  
  for(c in 1:mateChoiceCycles){
    
    # Calculate Reward 
    mReward <- rcalc(mMVs, fChoice, mChoice)
    fReward <- rcalc(fMVs, mChoice, fChoice)
    
    # Choose Mate 
    mMaxReward <- cbind(1:nrow(males), apply(mReward, 1, which.max))
    fMaxReward <- cbind(1:nrow(females), apply(fReward, 1, which.max))
    
    
    
    # Update Choice Matrices
    mChoice[mMaxReward] <- mChoice[mMaxReward] + 1
    fChoice[fMaxReward] <- fChoice[fMaxReward] + 1
    
    
  
  }
  # Commit to Memory 
  

  # Store mReward & fReward in Reward Memory (of MaxReward mates?) and compare vector to memory

  # dont need these , m and freward IS rewVector. 
    mRewVector <- matrix(mReward, 
                         nrow(mRewVector), 
                         ncol(mRewVector), 
                         dimnames = colnames(mRewVector))
    
    fRewVector <- matrix(fReward, 
                         nrow(fRewVector), 
                         ncol(fRewVector), 
                         dimnames = colnames(fRewVector))


    
  # for males. Do same for females. 
    for(m in 1:nrow(males)){
      
      maxNow <- max(mReward[m, ])
      maxMemory <- max(mRewMemory[m, ])
      
      if(maxNow > maxMemory){
        
        mRewMemory[m, ] <- mReward[m, ]
        mPrefMemory[m, ] <- mPref[m, ]
        
      }
      
      
    }
    
    
}
  



# Correlation between learned prefernces and real prefernces. 

```

First sentence ; organisms have preferences that guide them to mate.

```{r}
# How Should Success be Calculated? It makes sense to calculate it as an "interest" ratio. (The interest you recieve from females: how many females chose me?) / (the interest you send to females: how many females I have pursued) seems like a mathimatical model that gets at the goodness of mate preference values. I am not sure that this is what is going on right now. Look into this. 
```
