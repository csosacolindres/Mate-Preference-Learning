---
title: "How To Learn Your Mate Preferences"
format: html
editor: visual
---

## Mate Preference Learning

**Purpose**: This model was designed to explore how might species-typical mating psychology give rise to individually tailored mate preferences. Using an agent-based model, we will test the ability of a reinforcement learning algorithm to reproduce the ideal mate preferences of N = 1,044 participants.

âœ… **Agents**: Each agent represents a participant. The agents are made up of 15 traits, an initial preference vector (10's across all traits), an initial reward vector (date mate value given preferences), memory for reward vector, memory for preference vector.

**Life Cycle:**

1.  Mate choice for n cycles using preference vector.

    1.  Each cycle, they choose a mate that maximizes mv\*received/sent

    2.  Store mv\*received/sent in memory for reward vector (needs to be constantly recalc)

    3.  Preference vector goes into preference memory

2.  Change preferences relative to memory by methods:

    1.  Random

    2.  Decreased fixed amount (need to code diff for this)

    3.  Move towards highest reward partner (and this)

3.  Mate choice for n cycles using changed preference vector

    1.  Compare max reward to max reward stored in memory (do new preferences do better than old preferences?)

        1.  If better: Store new preferences in memory & store reward in memory

        2.  If not better: Keep memory unchanged; discard new preference & reward vector.

4.  Cycle back to #2 (change preferences relative to memory by methods---for now only Random) until preferences are no longer changing.

```{r parameters}

# the 15 Traits
traitNames <- paste0(c("affectionate", 
                       "ambition", 
                       "artistic", 
                       "disposition", 
                       "family", 
                       "health", 
                       "humor", 
                       "intelligent", 
                       "kind", 
                       "parenting", 
                       "physatt", 
                       "religious", 
                       "resources", 
                       "sexy", 
                       "status"))

# Starting Values for Prefernces and Reward Memory. 
startPref <- 10
startRMem <- 0


# number of males and females
maleNum <- 458 
femaleNum <- 458

# All Methods
methodList <- c("randomMethod", "absoluteMethod", "absImpMethod", "magnitudeMethod", "magImpMethod", "allMagMethod", "magUpDownMethod")

# absolute method(s) subtracting amount from mate preferences
abValue <- c(NA,rep(.1,2),rep(.5,4))

# magnitude method(s) largest change value & probability of abValue going down vs up 
downProb <- c(rep(NA,6),.8)


# Cycles 
prefLearningCycles <- rep(150, 7)
prefTestingCycles <- rep(maleNum*3, 7)


#Combine all parameter settings into a matrix for looping
pMatrix<-data.frame("method"=methodList,
                    "abValue"=abValue,
                    "downProb"=downProb,
                    "prefLearningCycles"=prefLearningCycles,
                    "prefTestingCycles"=prefTestingCycles)


#Number of times to repeat each model
modelLoops<- 5

```

Functions

```{r}

# Mate Value Calculation : own pref vector, others trait composite
mvcalc <- function(pref, traits){
  names(pref) <- 1:15
  names(traits) <- 1:15
  mv <- 10 *(-1 *(dist(rbind(pref, traits))) + sqrt(10^2 *15)) / sqrt(10^2 *15)
  
  return(mv)
}



# Reward Calculation : interest recieved / interest sent 
rcalc <- function(mv, recieved, sent) {
  
  interestRatio <- t(recieved) / sent
  interestRatio[interestRatio>1.25]<-1.25
  reward <- mv * interestRatio 
  
  return(reward)
}




mpUpdate <- function(method = "method", pref, imp, abValue, downProb) {
  
  if(method == "randomMethod") {
    
    # Random Method: Selects 1 random trait to change. Changes selected trait to random mate preference value.
    
      random <- t(apply(pref, 1, function(y) round(runif(y, min = 0, max = 10), 1)))
      colnames(random) <- colnames(pref)
      
      changeMat <- cbind(1:nrow(pref), sample(1:15, nrow(pref), replace = T))
      pref[changeMat] <- random[changeMat]
    
    } 
  
  
  
  if(method == "absoluteMethod") {
      
      # Absolute Method: Selects all trait to change. Changes traits down by abValue amount.
    
      absolute <- pref - abValue 
      colnames(absolute) <- colnames(pref)
      
      changeMat <- cbind(1:nrow(pref), sample(1:15, nrow(pref), replace = T))
      pref[changeMat] <- absolute[changeMat]
    
    }
  

  
  if(method == "absImpMethod") {
    
    # Absolute-Importance Method: Selects a trait to change proportional to how important the traitt is to the specific participant. Changes selected trait down by abValue.  
    
      absolute <- pref - abValue 
      colnames(absolute) <- colnames(pref)
      
      changeVec <- apply(imp, 1, function(x) sample(1:15, 1, prob = 11 - x))
      changeMat <- cbind(1:nrow(pref), changeVec)
      pref[changeMat] <- absolute[changeMat]
    
    }
    
  
  
  if(method == "allMagMethod"){
        
    # All-Magnitude Method: Selects all traits. Changes values down by mag (a value proportional to importance with a max amount that preference value can change). More important traits go down less amount. Less important traits go down less amount.
    
    mag <- ((11-imp)/11) * abValue
    
    pref <- pref - mag
  }
  
  
  
  if(method == "magnitudeMethod") {
    
        
    # Magnitude Method: Selects 1 trait at random. Changes values down by mag (a value proportional to importance and a max amount that preference value decreses by). More important traits go down less amount. Less important traits go down less amount.
    
    mag <- ((11-imp)/11) * abValue
    magnitude <- pref - mag
    
    changeVec <- apply(imp, 1, function(x) sample(1:15, 1))
    changeMat <- cbind(1:nrow(pref), changeVec)
    pref[changeMat] <- magnitude[changeMat]
  
    }
  
  
  
  if(method == "magImpMethod") {
  
    # Magnitude-Importance Method: Selects 1 trait proportional to how important the trait is (if more important, less likley to be picked. If less important, more likely to be picked). The the preference values decrease by mag (a value proportional to importance and a max amount that preference value decreases by). More important traits decrease less. Less important traits decrease more. 
    
    mag <- ((11-imp)/11) * abValue
    magnitude <- pref - mag
    
    changeVec <- apply(imp, 1, function(x) sample(1:15, 1, prob = 11 - x))
    changeMat <- cbind(1:nrow(pref), changeVec)
    pref[changeMat] <- magnitude[changeMat]
    
    }
  
  
  
  if(method == "magUpDownMethod"){
   
    # Magnitude Up-Down Method: Selects all traits. This can decrease and increase preference values. The traits increase or decrease depending on a weighted proportion (downProb). The preference values decrease by mag (a value proportional to importance and a max amount that preference value decreases by) where ore important traits decrease less. Less important traits decrease more. The preference values increase by mag where the more important traits increase more and the less important traits increase less. 
    
    if(rbinom(1, 1, prob = downProb)){
      
      mag <- ((11-imp)/11) * abValue
      pref <- pref - mag
      
    } else {
       
      mag <- ((imp + 1)/11) * abValue
      
      pref <- pref + mag
      pref[pref > 10] <- 10
       
    }
      
  }
  
 
  return(pref)
}


```

Agent Generation

```{r}

data <- read.csv("Human_data.csv")
data <- data[complete.cases(data[, c(6, 235:249, 345:359, 283:297, 299:213)]),]
data <- data[data$CIN %in% data$CIN[duplicated(data$CIN)],]

# seperating into sexes
females <- data[data$sex == 0, c(1,3:4,235:249,283:297,345:359)]
males <- data[data$sex == 1, c(1,3:4,235:249,283:297,345:359)]

# number of participants
females <- females[sample(1:nrow(females), femaleNum),]
males <- males[sample(1:nrow(males), maleNum),]

# participant's traits 
mTraits <- as.matrix(males[, c(34:48)])
fTraits <- as.matrix(females[, c(34:48)])

# participant's importance ratings 
fImp <- as.matrix(females[, c(19:33)])
mImp <- as.matrix(males[, c(19:33)])

```

# Simulation:

```{r}


# Create a dataframe for storing trial-by-trial correlations between learned and real preferences
trialCors <- data.frame(matrix(NA,1,8))
colnames(trialCors)<-c("o",colnames(pMatrix),"trial","r")

prefData<-data.frame(matrix(NA,1,54))
colnames(prefData)<-c("o",colnames(pMatrix),
                      colnames(females)[1:3],
                      paste0("obs_",traitNames),
                      paste0("imp_",traitNames),
                      paste0("learned_",traitNames))



#Loop each model m times
for (o in 1:modelLoops) {
  for (p in 1:nrow(pMatrix)) {
    # re-sets inital traits after a method; if not: old method pref updates will stay for next update method. I dont want that.
    
    fPref <- matrix(startPref, nrow(females), 15)
    colnames(fPref) <- traitNames
    
    fPrefMemory <- matrix(startPref, nrow(females), 15)
    colnames(fPrefMemory) <- traitNames
    
    fRewMemory <- matrix(startRMem, nrow(females), nrow(males))
    
    
    mPref <- matrix(startPref, nrow(males), 15)
    colnames(mPref) <- traitNames
    
    mPrefMemory <- matrix(startPref, nrow(males), 15)
    colnames(mPrefMemory) <- traitNames
    
    mRewMemory <- matrix(startRMem, nrow(males), nrow(females))
    
    
    # method cycled
    method <- pMatrix$method[p]
    
    
    for (l in 1:pMatrix$prefLearningCycles[p]) {
      # makes sure the right method is being used.
      if (l > 1) {
        fPref <- mpUpdate(
          pMatrix$method[p],
          pref = fPref,
          imp = fImp,
          abValue = pMatrix$abValue[p],
          downProb = pMatrix$downProb[p]
        )
        
        mPref <- mpUpdate(
          pMatrix$method[p],
          pref = mPref,
          imp = mImp,
          abValue = pMatrix$abValue[p],
          downProb = pMatrix$downProb[p]
        )
      }
      
      
      
      # Calculate MV
      fMV <- t(apply(fPref, 1, function(x)
        apply(mTraits, 1, function (y)
          mvcalc(x, y))))
      
      mMV <- t(apply(mPref, 1, function(x)
        apply(fTraits, 1, function(y)
          mvcalc(x, y))))
      
      
      
      # Create choice matrices:
      fChoice <- matrix(1, nrow(females), nrow(males))
      mChoice <- matrix(1, nrow(males), nrow(females))
      
      for (t in 1:pMatrix$prefTestingCycles[p]) {
        # Calculate Reward
        fReward <- rcalc(fMV, mChoice, fChoice)
        mReward <- rcalc(mMV, fChoice, mChoice)
        
        # Choose Mate
        fMaxReward <-
          cbind(1:nrow(females), apply(fReward, 1, which.max))
        mMaxReward <-
          cbind(1:nrow(males), apply(mReward, 1, which.max))
        
        # Update Choice Matrices
        fChoice[fMaxReward] <- fChoice[fMaxReward] + 1
        mChoice[mMaxReward] <- mChoice[mMaxReward] + 1
        
      }
      
      
      
      # Commit to Memory. If new reward is higher than old reward, replace old mate preference set with new mate preference set. If not, keep old mate preference set.
      for (f in 1:nrow(females)) {
        maxNow <- max(fReward[f,])
        maxMemory <- max(fRewMemory[f,])
        
        if (maxNow >= maxMemory) {
          fRewMemory[f,] <- fReward[f,]
          fPrefMemory[f,] <- fPref[f,]
          
        } else {
          fPref[f,] <- fPrefMemory[f,]
          
        }
        
      }
      
      
      for (m in 1:nrow(males)) {
        maxNow <- max(mReward[m,])
        maxMemory <- max(mRewMemory[m,])
        
        if (maxNow >= maxMemory) {
          mRewMemory[m,] <- mReward[m,]
          mPrefMemory[m,] <- as.numeric(mPref[m,])
          
        } else {
          mPref[m,] <- mPrefMemory[m,]
          
        }
        
      }
      
      
      #Compute the average correlation between learned and observed preferences
      
      r <-
        suppressWarnings(mean(diag(cor(
          rbind(fPref, mPref), rbind(females[, 4:18], males[, 4:18])
        ))))
      
      r <- ifelse(is.na(r), 0, r)
      
      # Saves trial by trial correlations for each method being used.
      trialCors <- rbind(trialCors, cbind(o, pMatrix[p, ], "trial" = l, r))
      
    }
    
    
    #Prepare learned preferences for saving
    fPref <-
      suppressWarnings(cbind(o, pMatrix[p, ], females[, 1:33], fPref))
    mPref <-
      suppressWarnings(cbind(o, pMatrix[p, ], males[, 1:33], mPref))
    
    colnames(fPref) <- colnames(prefData)
    colnames(mPref) <- colnames(prefData)
    
    prefData <- rbind(prefData, fPref, mPref)
    
  }
  
}

#Remove the unnecessary rows of NAs from the results dataframes
trialCors<-trialCors[-1,]
prefData<-prefData[-1,]

write.csv(trialCors, file = paste0("TrialCorrelationResults", Sys.time(), " .csv"))
write.csv(prefData, file = paste0("PrefDataResults", Sys.time(), " .csv"))

```

Stats

```{r}

# cut this to 20 model runs. present that. 
# maek new data frame == trial cors where o = 1


plotCors <- trialCors[trialCors$o==1, ]
# average performace across all teh model loops.
plotCors$r <- c(tapply(trialCors$r, list(trialCors$trial, trialCors$method), mean))

# plot 
ggplot(plotCors, mapping = aes(x = trial, y = r, color = method)) + geom_smooth() + labs(x = "Adjustment Trials", y = expression(italic("r")["Learned, Real Preferences"])) + scale_color_discrete(name = "Adjustment Method", labels = c("Imp-Set", "Random-Set", "All-Imp", "Imp-Imp", "Random-Imp", "All-Prob&Imp", "Random-Random")) + theme_grey(base_size = 13.5)


# do similar thing for sex differernces. 

```
